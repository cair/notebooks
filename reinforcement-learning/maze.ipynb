{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_maze\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 state_size, \n",
    "                 action_size, \n",
    "                 batch_size=32, \n",
    "                 lr=0.0001,\n",
    "                 dr=0.99,\n",
    "                 memory_size=20000, \n",
    "                 epsilon_min=0.01, \n",
    "                 epsilon_max=1.0\n",
    "                 ):\n",
    "        self.lr = lr\n",
    "        self.dr = dr\n",
    "        self.memory = deque(maxlen=memory_size)  # Experience replay buffer\n",
    "        self.e = 1.0  # Start value of epsilon decent\n",
    "        self.e_max = epsilon_max\n",
    "        self.e_min = epsilon_min\n",
    "        self.e_decay = 0.999\n",
    "        self.s_space = state_size[1:]\n",
    "        self.a_space = action_size\n",
    "        self.b_size = 32\n",
    "        self.model = None\n",
    "     \n",
    "    def build_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(64, (4, 4), \n",
    "                         padding=\"same\", \n",
    "                         strides=(4, 4), \n",
    "                         activation=\"relu\", \n",
    "                         input_shape=self.s_space, \n",
    "                         data_format=\"channels_last\")\n",
    "                  )\n",
    "\n",
    "        self.model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(4, 4), activation=\"relu\",))\n",
    "        self.model.add(Conv2D(64, (2, 2), padding=\"same\", strides=(4, 4), activation=\"relu\",))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512,  activation=\"relu\"))\n",
    "        self.model.add(Dense(self.a_space, activation='linear'))\n",
    "    \n",
    "        # DQN.huber_loss\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=self.lr))  # Consider using Huber Loss\n",
    "\n",
    "        return display(SVG(model_to_dot(self.model, show_shapes=True).create(prog='dot', format='svg')))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.e:\n",
    "            return np.random.randint(0, self.a_space)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory) < self.b_size:\n",
    "            return\n",
    "        \n",
    "        # Retrieve random sequence of memory indexes\n",
    "        random_experience_idxs = np.random.choice(len(self.memory), size=self.b_size)\n",
    "        \n",
    "        # Get actual memory data into a mini batch\n",
    "        mini_batch = [self.memory[idx] for idx in random_experience_idxs]\n",
    "        \n",
    "        # Iterate over all memories\n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "\n",
    "            # While not in terminal state\n",
    "            if not done:\n",
    "                # Q-Update RUle\n",
    "                target = (reward + self.dr * np.amax(self.model.predict(next_state)[0]))\n",
    "            else:\n",
    "                # End of sequence\n",
    "                target = reward\n",
    "            \n",
    "            # Predict pi* using s0\n",
    "            target_f = self.model.predict(state)\n",
    "            \n",
    "            # Update old with new target\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            # Train weights\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        # Epsilon descent\n",
    "        if self.e > self.e_min:\n",
    "            self.e *= self.e_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a few parameters\n",
    "lr = 0.0001  # Learning rate\n",
    "dr = 0.99  # Discount rate\n",
    "\n",
    "episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "environment = gym.make('maze-v0')\n",
    "environment.render()  # Render initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = DQN(environment.observation_space.shape, environment.action_space.shape, lr=lr, dr=dr)\n",
    "agent.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset environment to start state\n",
    "s = environment.reset()\n",
    "\n",
    "for episode in range(episodes):\n",
    "    \n",
    "    t = False\n",
    "    \n",
    "    while not t:\n",
    "        \n",
    "        # Draw environment\n",
    "        environment.render()\n",
    "        \n",
    "        a = agent.act(s)\n",
    "        \n",
    "        s1, r, t, _ = environment.step(a)\n",
    "        \n",
    "        agent.memory.append((s, a, r, s1, t))\n",
    "        \n",
    "        agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
